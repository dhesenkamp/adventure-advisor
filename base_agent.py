from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.memory import ConversationSummaryBufferMemory


class BaseAgent:

  FALLBACK_PROMPT = (
      "You are a helpful assistant."
      "Chat history: {history}\n\n"
      "Answer the user: {input}\n\n"
      "Your scratchpad: {agent_scratchpad}"
  )

  def __init__(self, apiKey: str, tools: list = list(), promptTemplate: str | None = None):
    """Agent base class using the LangChain API. 
    Steps to instantiate an agent executor:
    1. Define tools
    2. Create LLM instance
    3. Create a prompt template (include history key)
    4. Create runnable with llm, tools, prompt
    5. Create memory with llm
    6. Create agent executor with agent, tools, memory

    Args:
        apiKey (str): API key for the LLM model, default is Google's Gemini
        tools (list): List of custom tools to be bound to the agent. Need to be decorated with @tool.
        promptTemplate (str | None): Custom prompt template for the agent. If None, a simple default template is used.
    """
    self.tools = tools
    self.llm = self._loadModel(apiKey)
    self.prompt = self._buildPrompt(promptTemplate)
    self.executor = self._buildExecutor()

  def _loadModel(self, apiKey) -> ChatGoogleGenerativeAI:
    """Load a specific model using LangChain wrapper. Model parameters can be changed here."""
    return ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        api_key=apiKey
    )

  def _buildPrompt(self, promptTemplate: str | None) -> ChatPromptTemplate:
    """Build a prompt template for the agent using the LangChain wrapper. A simple default template is used if no custom template is provided."""

    if promptTemplate is None:
      promptTemplate = self.FALLBACK_PROMPT
    return ChatPromptTemplate.from_template(
        promptTemplate
    )

  def _buildMemory(self) -> ConversationSummaryBufferMemory:
    """Build a memory for the agent using the LangChain wrapper."""
    return ConversationSummaryBufferMemory(
        llm=self.llm,
        memory_key="history",
        return_messages=True,
        max_token_limit=1000,
        input_key="input",
        output_key="output"
    )

  def _buildAgent(self):
    return create_tool_calling_agent(
        llm=self.llm,
        tools=self.tools,
        prompt=self.prompt,
    )

  def _buildExecutor(self):
    """Build the agent executor with the agent, tools, and memory."""
    return AgentExecutor(
        agent=self._buildAgent(),
        tools=self.tools,
        memory=self._buildMemory(),
    )

  def run(self, query: str) -> dict:
    """Run agent with a user query. The query is passed to the LLM and the result is returned as a dict. Get the natural language result with key "output" and the tool call with the key "tool_call".
    """
    today = datetime.now().strftime("%Y-%m-%d")
    return self.executor.invoke({"input": query, "today": today})

  def getChatSummary(self):
    """Get a summary of the chat history. The summary is generated by the LLM and returned as a string."""
    return self.executor.memory.chat_memory
